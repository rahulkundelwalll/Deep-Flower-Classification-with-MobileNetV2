{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Petals to the Metal - Flower Classification \nIn this Getting Started competition (what is a Getting Started competition?), we're classifying 104 types of flowers based on their images drawn from five different public datasets. Some classes are very narrow, containing only a particular sub-type of flower (e.g. pink primroses) while other classes contain many sub-types (e.g. wild roses).\n\nThe dataset contains imperfections - images of flowers in odd places, or as a backdrop to modern machinery - but that's part of the challenge! Build a classifier than can see past all that, to the flowers at the heart of the images.\n\nFiles\nThis competition provides its files in TFRecord format. The TFRecord format is a container format frequently used in Tensorflow to group and shard data data files for optimal training performace.\nEach file contains the id, label (the class of the sample, for training data) and img (the actual pixels in array form) information for many images.\nPlease see our Getting Started notebook or our Learn exercise for notes on how to load and use them! Additional information is available in the TPU documentation.\n\ntrain/*.tfrec - training samples, including labels.\n\nval/*.tfrec - pre-split training samples w/ labels intended to help with checking your model's performance on TPU. The split was stratified across labels.\n\ntest/*.tfrec - samples without labels - you'll be predicting what classes of flowers these fall into.\n\nsample_submission.csv - a sample submission file in the correct format\n\nid - a unique ID for each sample.\n\nlabel - (in training data) the class of flower represented by the sample","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-20T15:56:35.163702Z","iopub.execute_input":"2023-09-20T15:56:35.164109Z","iopub.status.idle":"2023-09-20T15:56:35.357452Z","shell.execute_reply.started":"2023-09-20T15:56:35.164080Z","shell.execute_reply":"2023-09-20T15:56:35.356481Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/tpu-getting-started/sample_submission.csv\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/09-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/14-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/01-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/13-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/00-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/07-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/12-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/11-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/05-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/04-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/15-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/06-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/02-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/03-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/08-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val/10-224x224-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/04-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/06-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/05-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/08-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/15-224x224-452.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/09-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/10-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/07-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/00-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/01-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/12-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/14-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/03-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/02-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/11-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/test/13-224x224-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/13-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/11-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/05-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/00-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/02-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/14-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/06-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/10-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/01-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/03-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/08-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/09-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/15-224x224-783.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/07-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/04-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train/12-224x224-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/05-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/08-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/01-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/03-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/13-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/10-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/07-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/04-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/14-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/15-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/12-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/11-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/02-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/00-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/06-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/val/09-331x331-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/14-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/13-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/03-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/05-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/09-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/04-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/01-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/11-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/07-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/08-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/00-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/02-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/15-331x331-452.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/10-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/12-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/test/06-331x331-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/15-331x331-783.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/02-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/14-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/04-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/08-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/12-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/03-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/05-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/00-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/06-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/07-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/09-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/10-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/01-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/13-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-331x331/train/11-331x331-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/05-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/07-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/15-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/08-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/06-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/00-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/11-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/04-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/09-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/02-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/10-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/12-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/14-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/13-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/03-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/01-192x192-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/06-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/12-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/08-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/07-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/00-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/03-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/13-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/05-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/01-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/14-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/10-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/04-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/15-192x192-452.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/09-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/11-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/02-192x192-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/06-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/11-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/12-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/03-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/09-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/08-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/04-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/05-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/14-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/07-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/13-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/15-192x192-783.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/02-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/10-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/01-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/00-192x192-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/02-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/12-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/09-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/00-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/13-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/03-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/14-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/04-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/10-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/05-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/08-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/11-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/07-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/15-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/01-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/val/06-512x512-232.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/15-512x512-452.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/02-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/03-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/01-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/00-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/13-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/07-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/10-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/04-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/14-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/09-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/08-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/11-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/05-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/06-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/test/12-512x512-462.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/05-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/00-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/11-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/15-512x512-783.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/10-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/12-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/01-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/14-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/13-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/07-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/03-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/06-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/08-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/02-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/09-512x512-798.tfrec\n/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/train/04-512x512-798.tfrec\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import Tools","metadata":{}},{"cell_type":"code","source":"!pip install tfrecord","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:12.830769Z","iopub.execute_input":"2023-09-20T05:39:12.831464Z","iopub.status.idle":"2023-09-20T05:39:25.829990Z","shell.execute_reply.started":"2023-09-20T05:39:12.831429Z","shell.execute_reply":"2023-09-20T05:39:25.828819Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting tfrecord\n  Downloading tfrecord-1.14.4-py3-none-any.whl (15 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tfrecord) (1.23.5)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from tfrecord) (3.20.3)\nCollecting crc32c (from tfrecord)\n  Downloading crc32c-2.3.post0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: crc32c, tfrecord\nSuccessfully installed crc32c-2.3.post0 tfrecord-1.14.4\n","output_type":"stream"}]},{"cell_type":"code","source":"import tfrecord\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:25.832712Z","iopub.execute_input":"2023-09-20T05:39:25.833106Z","iopub.status.idle":"2023-09-20T05:39:29.183836Z","shell.execute_reply.started":"2023-09-20T05:39:25.833070Z","shell.execute_reply":"2023-09-20T05:39:29.182682Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:29.185604Z","iopub.execute_input":"2023-09-20T05:39:29.186955Z","iopub.status.idle":"2023-09-20T05:39:29.192193Z","shell.execute_reply.started":"2023-09-20T05:39:29.186913Z","shell.execute_reply":"2023-09-20T05:39:29.191113Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\n # you can list the bucket with \"!gsutil ls $GCS_DS_PATH\"","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:29.195240Z","iopub.execute_input":"2023-09-20T05:39:29.195586Z","iopub.status.idle":"2023-09-20T05:39:29.205640Z","shell.execute_reply.started":"2023-09-20T05:39:29.195554Z","shell.execute_reply":"2023-09-20T05:39:29.204775Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:29.207017Z","iopub.execute_input":"2023-09-20T05:39:29.207644Z","iopub.status.idle":"2023-09-20T05:39:29.720669Z","shell.execute_reply.started":"2023-09-20T05:39:29.207608Z","shell.execute_reply":"2023-09-20T05:39:29.719719Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport math, re, os\nimport numpy as np\n\n# import numpy as np\n\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:29.722033Z","iopub.execute_input":"2023-09-20T05:39:29.722523Z","iopub.status.idle":"2023-09-20T05:39:29.733597Z","shell.execute_reply.started":"2023-09-20T05:39:29.722487Z","shell.execute_reply":"2023-09-20T05:39:29.727381Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Tensorflow version 2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"GCS_DS_PATH  = '/kaggle/input/tpu-getting-started'","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:29.735319Z","iopub.execute_input":"2023-09-20T05:39:29.735652Z","iopub.status.idle":"2023-09-20T05:39:29.740745Z","shell.execute_reply.started":"2023-09-20T05:39:29.735620Z","shell.execute_reply":"2023-09-20T05:39:29.739734Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"GCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-224x224'","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:29.742601Z","iopub.execute_input":"2023-09-20T05:39:29.742943Z","iopub.status.idle":"2023-09-20T05:39:29.751252Z","shell.execute_reply.started":"2023-09-20T05:39:29.742913Z","shell.execute_reply":"2023-09-20T05:39:29.750366Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Import TensorFlow into colab\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nprint(\"TF version :\", tf.__version__)\nprint(\"TF version :\", hub.__version__)\n\n# Check for GPU availability\nprint(\"GPU\" , \"available (YES!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:29.752801Z","iopub.execute_input":"2023-09-20T05:39:29.753144Z","iopub.status.idle":"2023-09-20T05:39:29.807679Z","shell.execute_reply.started":"2023-09-20T05:39:29.753114Z","shell.execute_reply":"2023-09-20T05:39:29.806431Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"TF version : 2.12.0\nTF version : 0.12.0\nGPU available (YES!!!)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading Data and convert it into Image and making CSV File of image_path and Labels","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport cv2\nimport pandas as pd\n\n# Function to decode TFRecord to image and label\ndef decode_tfrecord(record):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(record, LABELED_TFREC_FORMAT)  # Fix indentation here\n    image = tf.image.decode_jpeg(example['image'], channels=3)\n    label = tf.cast(example['class'], tf.int32)  # Fix label key here\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:29.811264Z","iopub.execute_input":"2023-09-20T05:39:29.811533Z","iopub.status.idle":"2023-09-20T05:39:29.819571Z","shell.execute_reply.started":"2023-09-20T05:39:29.811508Z","shell.execute_reply":"2023-09-20T05:39:29.818652Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Set the paths for input TFRecord files and output folder\ninput_tfrecord_dir = '/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/train'\noutput_image_dir = '/kaggle/working/Train_output'\ncsv_filename = '/kaggle/working/train.csv'\n\nos.makedirs(output_image_dir, exist_ok=True)\n\n# Create a CSV file to store image names and labels\ncsv_data = {'Image_Name': [], 'Label': []}\n\n# Loop through the input TFRecord files\nfor filename in os.listdir(input_tfrecord_dir):\n    input_file = os.path.join(input_tfrecord_dir, filename)\n\n    # Create a TFRecord dataset from the file\n    dataset = tf.data.TFRecordDataset(input_file)\n    # print(type(dataset))\n    # break\n    # dataset = dataset.repeat()\n\n    # Iterate through the records and decode them\n    # count = 0\n    for record in dataset:\n\n        # count += 1\n        image, label = decode_tfrecord(record)\n\n        # Save the image to the output folder\n        image_filename = os.path.join(output_image_dir, f\"{len(csv_data['Image_Name'])}.jpg\")\n        cv2.imwrite(image_filename, cv2.cvtColor(image.numpy(), cv2.COLOR_RGB2BGR))\n\n        # Record the image name and label\n        csv_data['Image_Name'].append(os.path.basename(image_filename))\n        csv_data['Label'].append(label.numpy())\n\n# Create a DataFrame and save it as a CSV file\ndf = pd.DataFrame(csv_data)\ndf.to_csv(csv_filename, index=False)\n\nprint(\"Images saved and CSV file created.\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:39:29.821203Z","iopub.execute_input":"2023-09-20T05:39:29.821887Z","iopub.status.idle":"2023-09-20T05:40:25.996980Z","shell.execute_reply.started":"2023-09-20T05:39:29.821838Z","shell.execute_reply":"2023-09-20T05:40:25.995899Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Images saved and CSV file created.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the paths for input TFRecord files and output folder\ninput_tfrecord_dir = '/kaggle/input/tpu-getting-started/tfrecords-jpeg-224x224/val'\noutput_image_dir = '/kaggle/working/val_output'\ncsv_filename = '/kaggle/working/val.csv'\n\nos.makedirs(output_image_dir, exist_ok=True)\n\n# Create a CSV file to store image names and labels\ncsv_data = {'Image_Name': [], 'Label': []}\n\n# Loop through the input TFRecord files\nfor filename in os.listdir(input_tfrecord_dir):\n    input_file = os.path.join(input_tfrecord_dir, filename)\n\n    # Create a TFRecord dataset from the file\n    dataset = tf.data.TFRecordDataset(input_file)\n    # print(type(dataset))\n    # break\n    # dataset = dataset.repeat()\n\n    # Iterate through the records and decode them\n    # count = 0\n    for record in dataset:\n\n        # count += 1\n        image, label = decode_tfrecord(record)\n\n        # Save the image to the output folder\n        image_filename = os.path.join(output_image_dir, f\"aug{len(csv_data['Image_Name'])}.jpg\")\n        cv2.imwrite(image_filename, cv2.cvtColor(image.numpy(), cv2.COLOR_RGB2BGR))\n\n        # Record the image name and label\n        csv_data['Image_Name'].append(os.path.basename(image_filename))\n        csv_data['Label'].append(label.numpy())\n\n# Create a DataFrame and save it as a CSV file\ndf = pd.DataFrame(csv_data)\ndf.to_csv(csv_filename, index=False)\n\nprint(\"Images saved and CSV file created.\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:40:25.999283Z","iopub.execute_input":"2023-09-20T05:40:25.999761Z","iopub.status.idle":"2023-09-20T05:40:39.754759Z","shell.execute_reply.started":"2023-09-20T05:40:25.999690Z","shell.execute_reply":"2023-09-20T05:40:39.753782Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Images saved and CSV file created.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport cv2\nfrom tqdm import tqdm  # Optional for progress tracking\n\n# Define the path to the input CSV file and the output directory\ncsv_file_path = \"/kaggle/working/train.csv\"\ninput_image_folder = \"/kaggle/working/Train_output/\"  # Update this to the actual image folder path\noutput_directory = \"/kaggle/working/augmented_images\"\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_directory, exist_ok=True)\n\n# Load the CSV data into a pandas DataFrame\ndf = pd.read_csv(csv_file_path)\n\n# Function to perform image augmentation and save to the output directory\n\n\ndef augment_and_save(image_name, label, unique_id, brightness_factor=1.0):\n    image_path = os.path.join(input_image_folder, image_name)\n    image = cv2.imread(image_path)\n    \n    # Perform image augmentation operations here\n    # Example: Rotate the image by 90 degrees\n    augmented_image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    \n    # Adjust brightness\n    augmented_image = np.clip(augmented_image * brightness_factor, 0, 255).astype(np.uint8)\n    \n    # Create a new filename for the augmented image\n    augmented_filename = f\"augment_{unique_id}_{image_name}\"\n    augmented_image_path = os.path.join(output_directory, augmented_filename)\n    \n    # Save the augmented image\n    cv2.imwrite(augmented_image_path, augmented_image)\n    \n    # Append the filename and label to a new CSV\n    augmented_data.append([augmented_filename, label])\n\n# Create a list to store augmented data\naugmented_data = []\n\n# Loop through the CSV data and apply augmentation with different brightness levels\nbrightness_factors = [0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]  # You can adjust these values\nfor index, row in tqdm(df.iterrows(), total=len(df), desc=\"Augmenting Images\"):\n    image_name = row['Image_Name']\n    label = row['Label']\n    \n    # Generate a unique ID for each image\n    unique_id = index  # You can use a different method to generate IDs\n    \n    # Apply augmentation with different brightness levels\n    for brightness_factor in brightness_factors:\n        augment_and_save(image_name, label, unique_id, brightness_factor)\n\n# Create a new DataFrame for the augmented data\naugmented_df = pd.DataFrame(augmented_data, columns=['Image_Name', 'Label'])\n\n# Save the augmented DataFrame to a new CSV file\naugmented_csv_file = \"/kaggle/working/augmented_data.csv\"\naugmented_df.to_csv(augmented_csv_file, index=False)\n\nprint(\"Augmentation and CSV creation complete.\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:40:39.756254Z","iopub.execute_input":"2023-09-20T05:40:39.756849Z","iopub.status.idle":"2023-09-20T05:45:29.911800Z","shell.execute_reply.started":"2023-09-20T05:40:39.756815Z","shell.execute_reply":"2023-09-20T05:45:29.910712Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Augmenting Images: 100%|██████████| 12753/12753 [04:49<00:00, 44.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Augmentation and CSV creation complete.\n","output_type":"stream"}]},{"cell_type":"code","source":"# import numpy as np\n\n# # Function to perform image augmentation (including brightness) and save to the output directory\n# def augment_and_save(image_name, label, unique_id, brightness_factor=1.0):\n#     image_path = os.path.join(input_image_folder, image_name)\n#     image = cv2.imread(image_path)\n    \n#     # Perform image augmentation operations here\n#     # Example: Rotate the image by 90 degrees\n#     augmented_image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    \n#     # Adjust brightness\n#     augmented_image = np.clip(augmented_image * brightness_factor, 0, 255).astype(np.uint8)\n    \n#     # Create a new filename for the augmented image\n#     augmented_filename = f\"augment_{unique_id}_{image_name}\"\n#     augmented_image_path = os.path.join(output_directory, augmented_filename)\n    \n#     # Save the augmented image\n#     cv2.imwrite(augmented_image_path, augmented_image)\n    \n#     # Append the filename and label to a new CSV\n#     augmented_data.append([augmented_filename, label])\n\n# # Create a list to store augmented data\n# augmented_data = []\n\n# # Loop through the CSV data and apply augmentation with different brightness levels\n# brightness_factors = [0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]  # You can adjust these values\n# for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Augmenting Images\"):\n#     image_name = row['Image_Name']\n#     label = row['Label']\n    \n#     # Generate a unique ID for each image\n#     unique_id = index  # You can use a different method to generate IDs\n    \n#     # Apply augmentation with different brightness levels\n#     for brightness_factor in brightness_factors:\n#         augment_and_save(image_name, label, unique_id, brightness_factor)\n\n# # Create a new DataFrame for the augmented data\n# augmented_df = pd.DataFrame(augmented_data, columns=['Image_Name', 'Label'])\n\n# # Save the augmented DataFrame to a new CSV file\n# augmented_csv_file = \"/kaggle/working/augmented_data.csv\"\n# augmented_df.to_csv(augmented_csv_file, index=False)\n\n# print(\"Augmentation and CSV creation complete.\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:36.025070Z","iopub.execute_input":"2023-09-20T05:45:36.025444Z","iopub.status.idle":"2023-09-20T05:45:36.034397Z","shell.execute_reply.started":"2023-09-20T05:45:36.025413Z","shell.execute_reply":"2023-09-20T05:45:36.033333Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf1 = pd.read_csv(\"/kaggle/working/train.csv\")\ndf2 = pd.read_csv(\"/kaggle/working/val.csv\") \ndf3 = pd.read_csv(\"/kaggle/working/augmented_data.csv\") \n#z = pd.concat([df1, df2])\n# labels_csv = pd.concat([t, df3])","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:36.602500Z","iopub.execute_input":"2023-09-20T05:45:36.602901Z","iopub.status.idle":"2023-09-20T05:45:36.662648Z","shell.execute_reply.started":"2023-09-20T05:45:36.602849Z","shell.execute_reply":"2023-09-20T05:45:36.661558Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df1['Image_Name']='/kaggle/working/Train_output/'+df1['Image_Name']\ndf2['Image_Name']='/kaggle/working/val_output/'+df2['Image_Name']\ndf3['Image_Name']='/kaggle/working/augmented_images/'+df3['Image_Name']","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:37.276596Z","iopub.execute_input":"2023-09-20T05:45:37.277279Z","iopub.status.idle":"2023-09-20T05:45:37.301139Z","shell.execute_reply.started":"2023-09-20T05:45:37.277240Z","shell.execute_reply":"2023-09-20T05:45:37.300105Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"t = pd.concat([df1, df2],axis=0,ignore_index=True)\nlabels_csv = pd.concat([t, df3],axis=0,ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:37.973055Z","iopub.execute_input":"2023-09-20T05:45:37.973438Z","iopub.status.idle":"2023-09-20T05:45:37.982971Z","shell.execute_reply.started":"2023-09-20T05:45:37.973408Z","shell.execute_reply":"2023-09-20T05:45:37.981648Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"labels_csv","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:38.376356Z","iopub.execute_input":"2023-09-20T05:45:38.377108Z","iopub.status.idle":"2023-09-20T05:45:38.394339Z","shell.execute_reply.started":"2023-09-20T05:45:38.377073Z","shell.execute_reply":"2023-09-20T05:45:38.393261Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                               Image_Name  Label\n0                      /kaggle/working/Train_output/0.jpg     70\n1                      /kaggle/working/Train_output/1.jpg     67\n2                      /kaggle/working/Train_output/2.jpg     80\n3                      /kaggle/working/Train_output/3.jpg     82\n4                      /kaggle/working/Train_output/4.jpg     73\n...                                                   ...    ...\n105731  /kaggle/working/augmented_images/augment_12752...     64\n105732  /kaggle/working/augmented_images/augment_12752...     64\n105733  /kaggle/working/augmented_images/augment_12752...     64\n105734  /kaggle/working/augmented_images/augment_12752...     64\n105735  /kaggle/working/augmented_images/augment_12752...     64\n\n[105736 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_Name</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/Train_output/0.jpg</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/Train_output/1.jpg</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/Train_output/2.jpg</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/Train_output/3.jpg</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/Train_output/4.jpg</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>105731</th>\n      <td>/kaggle/working/augmented_images/augment_12752...</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>105732</th>\n      <td>/kaggle/working/augmented_images/augment_12752...</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>105733</th>\n      <td>/kaggle/working/augmented_images/augment_12752...</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>105734</th>\n      <td>/kaggle/working/augmented_images/augment_12752...</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>105735</th>\n      <td>/kaggle/working/augmented_images/augment_12752...</td>\n      <td>64</td>\n    </tr>\n  </tbody>\n</table>\n<p>105736 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n# labels_csv = pd.read_csv('/kaggle/working/train.csv')\nprint(labels_csv.describe())\nprint(labels_csv.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:38.941575Z","iopub.execute_input":"2023-09-20T05:45:38.942074Z","iopub.status.idle":"2023-09-20T05:45:38.974889Z","shell.execute_reply.started":"2023-09-20T05:45:38.942033Z","shell.execute_reply":"2023-09-20T05:45:38.973918Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"               Label\ncount  105736.000000\nmean       55.611041\nstd        30.615215\nmin         0.000000\n25%        32.000000\n50%        56.000000\n75%        78.000000\nmax       103.000000\n                           Image_Name  Label\n0  /kaggle/working/Train_output/0.jpg     70\n1  /kaggle/working/Train_output/1.jpg     67\n2  /kaggle/working/Train_output/2.jpg     80\n3  /kaggle/working/Train_output/3.jpg     82\n4  /kaggle/working/Train_output/4.jpg     73\n","output_type":"stream"}]},{"cell_type":"code","source":"labels_csv.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:39.373967Z","iopub.execute_input":"2023-09-20T05:45:39.374809Z","iopub.status.idle":"2023-09-20T05:45:39.421747Z","shell.execute_reply.started":"2023-09-20T05:45:39.374770Z","shell.execute_reply":"2023-09-20T05:45:39.420813Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"labels_csv.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:39.644460Z","iopub.execute_input":"2023-09-20T05:45:39.645195Z","iopub.status.idle":"2023-09-20T05:45:39.657966Z","shell.execute_reply.started":"2023-09-20T05:45:39.645154Z","shell.execute_reply":"2023-09-20T05:45:39.656911Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                           Image_Name  Label\n0  /kaggle/working/Train_output/0.jpg     70\n1  /kaggle/working/Train_output/1.jpg     67\n2  /kaggle/working/Train_output/2.jpg     80\n3  /kaggle/working/Train_output/3.jpg     82\n4  /kaggle/working/Train_output/4.jpg     73","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_Name</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/Train_output/0.jpg</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/Train_output/1.jpg</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/Train_output/2.jpg</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/Train_output/3.jpg</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/Train_output/4.jpg</td>\n      <td>73</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Create pathnames from image ID's\nfilenames = [ fname for fname in labels_csv[\"Image_Name\"]]\n\n# Check the first 10 filenames\nfilenames[:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:39.837226Z","iopub.execute_input":"2023-09-20T05:45:39.838269Z","iopub.status.idle":"2023-09-20T05:45:39.852274Z","shell.execute_reply.started":"2023-09-20T05:45:39.838225Z","shell.execute_reply":"2023-09-20T05:45:39.851329Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/Train_output/0.jpg',\n '/kaggle/working/Train_output/1.jpg',\n '/kaggle/working/Train_output/2.jpg',\n '/kaggle/working/Train_output/3.jpg',\n '/kaggle/working/Train_output/4.jpg',\n '/kaggle/working/Train_output/5.jpg',\n '/kaggle/working/Train_output/6.jpg',\n '/kaggle/working/Train_output/7.jpg',\n '/kaggle/working/Train_output/8.jpg',\n '/kaggle/working/Train_output/9.jpg']"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nlabels = labels_csv[\"Label\"].to_numpy() # convert labels column to NumPy array\nlabels[:10]","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:40.012455Z","iopub.execute_input":"2023-09-20T05:45:40.012820Z","iopub.status.idle":"2023-09-20T05:45:40.022088Z","shell.execute_reply.started":"2023-09-20T05:45:40.012789Z","shell.execute_reply":"2023-09-20T05:45:40.020952Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([70, 67, 80, 82, 73,  4, 49, 80, 77, 68])"},"metadata":{}}]},{"cell_type":"code","source":"# Find the unique label values\nunique_labels = np.unique(labels)\nlen(unique_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:40.192263Z","iopub.execute_input":"2023-09-20T05:45:40.193234Z","iopub.status.idle":"2023-09-20T05:45:40.202416Z","shell.execute_reply.started":"2023-09-20T05:45:40.193191Z","shell.execute_reply":"2023-09-20T05:45:40.201261Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"104"},"metadata":{}}]},{"cell_type":"code","source":"print(labels[0])\nlabels[0] == unique_labels # use comparison operator to create boolean array","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:40.353584Z","iopub.execute_input":"2023-09-20T05:45:40.354293Z","iopub.status.idle":"2023-09-20T05:45:40.364009Z","shell.execute_reply.started":"2023-09-20T05:45:40.354250Z","shell.execute_reply":"2023-09-20T05:45:40.361753Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"70\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"array([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False])"},"metadata":{}}]},{"cell_type":"code","source":"# Turn every label into a boolean array\nboolean_labels = [label == np.array(unique_labels) for label in labels]\nboolean_labels[:2]","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:40.531832Z","iopub.execute_input":"2023-09-20T05:45:40.532990Z","iopub.status.idle":"2023-09-20T05:45:40.629835Z","shell.execute_reply.started":"2023-09-20T05:45:40.532949Z","shell.execute_reply":"2023-09-20T05:45:40.628858Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[array([False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False,  True, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False]),\n array([False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False,  True, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False, False, False, False, False,\n        False, False, False, False, False])]"},"metadata":{}}]},{"cell_type":"code","source":"# Example: Turning a boolean array into integers\nprint(labels[0]) # original label\nprint(np.where(unique_labels == labels[0])[0][0]) # index where label occurs\nprint(boolean_labels[0].argmax()) # index where label occurs in boolean array\nprint(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:40.707766Z","iopub.execute_input":"2023-09-20T05:45:40.708820Z","iopub.status.idle":"2023-09-20T05:45:40.716891Z","shell.execute_reply.started":"2023-09-20T05:45:40.708774Z","shell.execute_reply":"2023-09-20T05:45:40.715832Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"70\n70\n70\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setup X & y variables\nX = filenames\ny = boolean_labels","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:40.893244Z","iopub.execute_input":"2023-09-20T05:45:40.894185Z","iopub.status.idle":"2023-09-20T05:45:40.899706Z","shell.execute_reply.started":"2023-09-20T05:45:40.894139Z","shell.execute_reply":"2023-09-20T05:45:40.898559Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"len(X)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:41.074888Z","iopub.execute_input":"2023-09-20T05:45:41.075262Z","iopub.status.idle":"2023-09-20T05:45:41.083923Z","shell.execute_reply.started":"2023-09-20T05:45:41.075233Z","shell.execute_reply":"2023-09-20T05:45:41.082928Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"29218"},"metadata":{}}]},{"cell_type":"code","source":"# Import train_test_split from Scikit-Learn\nfrom sklearn.model_selection import train_test_split\n\n# Split them into training and validation using NUM_IMAGES\nX_train, X_val, y_train, y_val = train_test_split(X,\n                                                  y,\n                                                  test_size=0.17,\n                                                  random_state=42)\n\nlen(X_train), len(y_train), len(X_val), len(y_val)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:41.285267Z","iopub.execute_input":"2023-09-20T05:45:41.287179Z","iopub.status.idle":"2023-09-20T05:45:42.024971Z","shell.execute_reply.started":"2023-09-20T05:45:41.287136Z","shell.execute_reply":"2023-09-20T05:45:42.023892Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(24250, 24250, 4968, 4968)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocessing Data","metadata":{}},{"cell_type":"code","source":"# Define image size\nIMG_SIZE = 224\n\ndef process_image(image_path):\n  \"\"\"\n  Takes an image file path and turns it into a Tensor.\n  \"\"\"\n  # Read in image file\n  image = tf.io.read_file(image_path)\n  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n  image = tf.image.decode_jpeg(image, channels=3)\n  # Convert the colour channel values from 0-225 values to 0-1 values\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  # Resize the image to our desired size (224, 244)\n  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n  return image","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:42.027069Z","iopub.execute_input":"2023-09-20T05:45:42.027519Z","iopub.status.idle":"2023-09-20T05:45:42.036980Z","shell.execute_reply.started":"2023-09-20T05:45:42.027483Z","shell.execute_reply":"2023-09-20T05:45:42.035936Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Create a simple function to return a tuple (image, label)\ndef get_image_label(image_path, label):\n  \"\"\"\n  Takes an image file path name and the associated label,\n  processes the image and returns a tuple of (image, label).\n  \"\"\"\n  image = process_image(image_path)\n  return image, label","metadata":{"execution":{"iopub.status.busy":"2023-09-20T05:45:42.038675Z","iopub.execute_input":"2023-09-20T05:45:42.039440Z","iopub.status.idle":"2023-09-20T05:45:42.047976Z","shell.execute_reply.started":"2023-09-20T05:45:42.039405Z","shell.execute_reply":"2023-09-20T05:45:42.046898Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Define the batch size, 32 is a good default\nBATCH_SIZE = 64\n\n# Create a function to turn data into batches\ndef create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n  \"\"\"\n  Creates batches of data out of image (x) and label (y) pairs.\n  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n  Also accepts test data as input (no labels).\n  \"\"\"\n  # If the data is a test dataset, we probably don't have labels\n  if test_data:\n    print(\"Creating test data batches...\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n    data_batch = data.map(process_image).batch(BATCH_SIZE)\n    return data_batch\n\n  # If the data if a valid dataset, we don't need to shuffle it\n  elif valid_data:\n    print(\"Creating validation data batches...\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                               tf.constant(y))) # labels\n    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n    return data_batch\n\n  else:\n    # If the data is a training dataset, we shuffle it\n    print(\"Creating training data batches...\")\n    # Turn filepaths and labels into Tensors\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                              tf.constant(y))) # labels\n\n    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n    data = data.shuffle(buffer_size=len(x))\n\n    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n    data = data.map(get_image_label)\n\n    # Turn the data into batches\n    data_batch = data.batch(BATCH_SIZE)\n  return data_batch","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:09.152343Z","iopub.execute_input":"2023-09-20T06:05:09.153071Z","iopub.status.idle":"2023-09-20T06:05:09.164137Z","shell.execute_reply.started":"2023-09-20T06:05:09.153034Z","shell.execute_reply":"2023-09-20T06:05:09.163044Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"train_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val, valid_data=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:10.026807Z","iopub.execute_input":"2023-09-20T06:05:10.027204Z","iopub.status.idle":"2023-09-20T06:05:10.345967Z","shell.execute_reply.started":"2023-09-20T06:05:10.027175Z","shell.execute_reply":"2023-09-20T06:05:10.344935Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Creating training data batches...\nCreating validation data batches...\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.element_spec, val_data.element_spec","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:10.777297Z","iopub.execute_input":"2023-09-20T06:05:10.777919Z","iopub.status.idle":"2023-09-20T06:05:10.785939Z","shell.execute_reply.started":"2023-09-20T06:05:10.777855Z","shell.execute_reply":"2023-09-20T06:05:10.784924Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"((TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None),\n  TensorSpec(shape=(None, 104), dtype=tf.bool, name=None)),\n (TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None),\n  TensorSpec(shape=(None, 104), dtype=tf.bool, name=None)))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Creating","metadata":{}},{"cell_type":"code","source":"# Setup input shape to the model\nINPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n\n# Setup output shape of the model\nOUTPUT_SHAPE = len(unique_labels) # number of unique labels\n\n# Setup model URL from TensorFlow Hub\nMODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\"","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:11.313346Z","iopub.execute_input":"2023-09-20T06:05:11.313764Z","iopub.status.idle":"2023-09-20T06:05:11.319192Z","shell.execute_reply.started":"2023-09-20T06:05:11.313731Z","shell.execute_reply":"2023-09-20T06:05:11.317937Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a function which builds a Keras model with dropout and L2 regularization\ndef create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL, dropout_rate=0.1, l2_regularization=0.001):\n    print(\"Building model with:\", MODEL_URL)\n\n    # Setup the model layers\n    model = tf.keras.Sequential([\n        hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n        tf.keras.layers.Dropout(rate=dropout_rate), # Dropout layer to prevent overfitting\n        tf.keras.layers.Dense(units=128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_regularization)), # Additional hidden layer with L2 regularization\n        tf.keras.layers.Dropout(rate=dropout_rate), # Dropout layer\n        tf.keras.layers.Dense(units=OUTPUT_SHAPE, activation=\"softmax\") # Layer 2 (output layer)\n    ])\n\n    # Compile the model\n    model.compile(\n        loss=tf.keras.losses.CategoricalCrossentropy(),\n        optimizer=tf.keras.optimizers.Adam(),\n        metrics=[\"accuracy\"]\n    )\n\n    # Build the model\n    model.build(INPUT_SHAPE)\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:11.879591Z","iopub.execute_input":"2023-09-20T06:05:11.880033Z","iopub.status.idle":"2023-09-20T06:05:11.889940Z","shell.execute_reply.started":"2023-09-20T06:05:11.879999Z","shell.execute_reply":"2023-09-20T06:05:11.888878Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Create a model and check its details\nIMAGE_SIZE=[224,224,3]\nmodel = create_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:12.492771Z","iopub.execute_input":"2023-09-20T06:05:12.493929Z","iopub.status.idle":"2023-09-20T06:05:15.475833Z","shell.execute_reply.started":"2023-09-20T06:05:12.493881Z","shell.execute_reply":"2023-09-20T06:05:15.474851Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Building model with: https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\nModel: \"sequential_4\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n keras_layer_4 (KerasLayer)  (None, 1001)              5432713   \n                                                                 \n dropout_8 (Dropout)         (None, 1001)              0         \n                                                                 \n dense_8 (Dense)             (None, 128)               128256    \n                                                                 \n dropout_9 (Dropout)         (None, 128)               0         \n                                                                 \n dense_9 (Dense)             (None, 104)               13416     \n                                                                 \n=================================================================\nTotal params: 5,574,385\nTrainable params: 141,672\nNon-trainable params: 5,432,713\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the TensorBoard notebook extension\n%load_ext tensorboard","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:15.477564Z","iopub.execute_input":"2023-09-20T06:05:15.479138Z","iopub.status.idle":"2023-09-20T06:05:15.485535Z","shell.execute_reply.started":"2023-09-20T06:05:15.479101Z","shell.execute_reply":"2023-09-20T06:05:15.484424Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n","output_type":"stream"}]},{"cell_type":"code","source":"import datetime\n\n# Create a function to build a TensorBoard callback\ndef create_tensorboard_callback():\n  # Create a log directory for storing TensorBoard logs\n  logdir = os.path.join(\"/kaggle/working\",\n                        # Make it so the logs get tracked whenever we run an experiment\n                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n  return tf.keras.callbacks.TensorBoard(logdir)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:15.487077Z","iopub.execute_input":"2023-09-20T06:05:15.487732Z","iopub.status.idle":"2023-09-20T06:05:15.497701Z","shell.execute_reply.started":"2023-09-20T06:05:15.487699Z","shell.execute_reply":"2023-09-20T06:05:15.496656Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Create early stopping (once our model stops improving, stop training)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n                                                  patience=3) # stops after 3 rounds of no improvements","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:15.500805Z","iopub.execute_input":"2023-09-20T06:05:15.501408Z","iopub.status.idle":"2023-09-20T06:05:15.515051Z","shell.execute_reply.started":"2023-09-20T06:05:15.501372Z","shell.execute_reply":"2023-09-20T06:05:15.514056Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 100","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:15.516475Z","iopub.execute_input":"2023-09-20T06:05:15.516940Z","iopub.status.idle":"2023-09-20T06:05:15.526282Z","shell.execute_reply.started":"2023-09-20T06:05:15.516911Z","shell.execute_reply":"2023-09-20T06:05:15.525287Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"STEPS_PER_EPOCH = len(X_train) // 32\n# Build a function to train and return a trained model\ndef train_model():\n  \"\"\"\n  Trains a given model and returns the trained version.\n  \"\"\"\n  # Create a model\n  model = create_model()\n\n  # Create new TensorBoard session everytime we train a model\n  tensorboard = create_tensorboard_callback()\n\n  # Fit the model to the data passing it the callbacks we created\n  model.fit(x=train_data,\n            epochs=NUM_EPOCHS,\n            validation_data=val_data,\n            validation_freq=1, # check validation metrics every epoch\n            callbacks=[early_stopping],\n         )\n\n  return model","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:15.731311Z","iopub.execute_input":"2023-09-20T06:05:15.732028Z","iopub.status.idle":"2023-09-20T06:05:15.738554Z","shell.execute_reply.started":"2023-09-20T06:05:15.731982Z","shell.execute_reply":"2023-09-20T06:05:15.737394Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Fit the model to the data\nmodel = train_model()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T06:05:16.396285Z","iopub.execute_input":"2023-09-20T06:05:16.396672Z","iopub.status.idle":"2023-09-20T06:12:33.602527Z","shell.execute_reply.started":"2023-09-20T06:05:16.396641Z","shell.execute_reply":"2023-09-20T06:12:33.601201Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Building model with: https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\nEpoch 1/100\n379/379 [==============================] - 34s 77ms/step - loss: 2.0185 - accuracy: 0.5713 - val_loss: 1.1648 - val_accuracy: 0.7536\nEpoch 2/100\n379/379 [==============================] - 28s 74ms/step - loss: 1.1265 - accuracy: 0.7517 - val_loss: 0.9894 - val_accuracy: 0.7919\nEpoch 3/100\n379/379 [==============================] - 28s 74ms/step - loss: 0.9453 - accuracy: 0.7953 - val_loss: 0.9405 - val_accuracy: 0.8041\nEpoch 4/100\n379/379 [==============================] - 28s 75ms/step - loss: 0.8520 - accuracy: 0.8176 - val_loss: 0.8935 - val_accuracy: 0.8090\nEpoch 5/100\n379/379 [==============================] - 29s 75ms/step - loss: 0.7891 - accuracy: 0.8360 - val_loss: 0.8730 - val_accuracy: 0.8166\nEpoch 6/100\n379/379 [==============================] - 28s 73ms/step - loss: 0.7443 - accuracy: 0.8478 - val_loss: 0.8495 - val_accuracy: 0.8281\nEpoch 7/100\n379/379 [==============================] - 28s 74ms/step - loss: 0.7119 - accuracy: 0.8535 - val_loss: 0.8343 - val_accuracy: 0.8259\nEpoch 8/100\n379/379 [==============================] - 29s 75ms/step - loss: 0.6868 - accuracy: 0.8621 - val_loss: 0.8338 - val_accuracy: 0.8251\nEpoch 9/100\n379/379 [==============================] - 28s 73ms/step - loss: 0.6644 - accuracy: 0.8674 - val_loss: 0.8193 - val_accuracy: 0.8289\nEpoch 10/100\n379/379 [==============================] - 28s 73ms/step - loss: 0.6519 - accuracy: 0.8669 - val_loss: 0.8224 - val_accuracy: 0.8351\nEpoch 11/100\n379/379 [==============================] - 28s 73ms/step - loss: 0.6435 - accuracy: 0.8704 - val_loss: 0.8169 - val_accuracy: 0.8299\nEpoch 12/100\n379/379 [==============================] - 28s 75ms/step - loss: 0.6316 - accuracy: 0.8751 - val_loss: 0.8386 - val_accuracy: 0.8233\nEpoch 13/100\n379/379 [==============================] - 29s 75ms/step - loss: 0.6250 - accuracy: 0.8765 - val_loss: 0.8443 - val_accuracy: 0.8263\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## we gain 82.6 percent Accuracy","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}